# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CeqeIZWTmYXHHWnyGKTRkk6DceKcHpPS
"""

import numpy as np
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
#to select no of layers,nodes,learning rate for best model we use keras tuners (generates hyper parameters)
from kerastuner.tuners import RandomSearch

!pip install numpy
!pip install pandas
!pip install keras
!pip install keras-tuner


df=pd.read_csv(r"C:\Users\chaitanya\OneDrive\Desktop\naresh it\New folder\cls note nit\ANN-using-python-main\ANN-using-python-main\forestfires.csv")
df.head()



df.pop('month')
df.head()

df.pop('day')
df.head()

from sklearn.preprocessing import LabelEncoder
label_encoder=LabelEncoder()
df['size_category']=label_encoder.fit_transform(df['size_category'])
df['size_category'].unique()
df.columns
x=df.iloc[:,0:28]
y=df.iloc[:,28]

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x=sc.fit_transform(x)



def build_model(hp):
  model=keras.Sequential()
  for i in range(hp.Int('num_layers',2,20)):
    model.add(layers.Dense(units=hp.Int('units_'+str(i),min_value=32,max_value=512,step=32),activation='relu'))
    model.add(layers.Dense(1,activation='linear'))
    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',[1e-2,1e-3,1e-4])),loss='mean_absolute_error',metrics=['mean_absolute_error'])
  return model

tuner=RandomSearch(build_model,objective='val_mean_absolute_error',max_trials=5,executions_per_trial=3)

tuner.search_space_summary()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

tuner.search(x_train,y_train,epochs=35,validation_data=(x_test,y_test))

tuner.results_summary()

#here score is mean absolute error, so which ever have least score we consider those hyperparameters